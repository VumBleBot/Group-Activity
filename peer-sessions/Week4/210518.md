# 4주차 회의록 및 멘토링(0518)

## 실험 결과

- BM25 변형 -> retriever 성능 향상
    - Attire BM 25
    - Attire BM 25 + Dense Retriever -> Hybrid Retriever
        - Top-3 90% acc

- Reader 쪽에서 성능 향상이 적음.
    - Random Masking
    - Span Masking
    - EM Token으로 feature 추가
    - Head(custom layer) 추가
        - 1D CNN
        - LSTM

## 문제점

- Pretrained Backbone에 너무 의존적이다 보니 Head를 아무리 커스텀해도 효과가 크지 않은 것 같다.
    - ETRI에서 배포하고 있는 KoBERT가 형태소가 tagging된 Tokenizer를 사용해서, 해당 모델 사용 시도해 보는게 어떨지
    - 말하는 바로는 일반 BERT보다 5%가 높긴 한데..

- F1에 비해 EM이 너무 낮다.
    - 후처리에 집중하는게 점수 높이는게 맞긴함
    - 다른 팀들은 간단한 모듈들을 추가하거나 기존에 있는걸 잘 튜닝한 방향으로 가지 않았을까 한다.
        - 연구의 느낌인데 연구의 일부가 아직 좀 부족한 것.
        - 기존의 안정적인 모델을 튜닝을 너무 많이 하지 않았나..
        - 전체적인 task에서는 불안정할수도 있다.
    - 모델을 건드리는 일들은 멘토님보다는 교수님들께 여쭤보는게 더 맞는 상황.
        - 이번 competition만 놓고 보면 점수가 아쉬울수는 있지만 유의미한 기간이었을 것임
        - 점수에 연연하지 않겠다면 좀 더 연구를 해보는 것도 괜찮음.
    - critical한 방법을 생각한다면 ner 태깅으로는 부족할듯?
        - GPT2나 QA의 answer에서 강화학습을 했더니 더 풍부한 어휘로 말하더라...
            - 코로나로 전화나 문의를 넣을 때 기존 챗봇으로는 대응이 안됨(코로나가 학습되어있지 않음) -> 강화학습으로 보정
        - 강화학습을 빼다 쓸 수 있는 모듈이 있지 않은지 찾아봄직함
        - 근데 강화학습 + NLP 모델이 잘 안나와서 TF로 되어있는 경우가 있긴함....
    - Bert Base로 정답 후보군을 추리고 큰 모델로 정확한 답을 추리는 것
        - 자주 쓰이는 방법이긴 함.
    - 근데 우리 팀은 새로운 아이디어를 많이 적용시켰기 때문에 general한 방법들에 스코어가 오를것이라고 확신하기 어려움(안먹힐 가능성이 높음)
        - 새로운 기법을 사용할 때, 일단 써보는게 아니라 우리가 커스텀한 모델과 궁합이 좋을지 고민을 더 해볼것

1. 점수보다는 모델에 대해 생각해보자
2. 논문으로 쓸 수 있는지 알아보자
3. 화이팅!

- 앙상블 시 soft voting하려고 하는데, token 기준으로 앙상블을 할수가 없음(모델마다 tokenizer가 달라서)
    - 그래서 offset을 기준으로 soft voting하려고 하는데 괜찮을까요?
    - 그렇게 하는거면 잘 될것같아요!
        - 근데 이 방식도 처음 듣는데, 그것도 글로 잘 정리해서 교수님들께 아이디어를 여쭤봐도 좋을것같아요.
    - 원래는 MRC에서 앙상블을 어떻게 하나요?
        - 같은 토크나이저에 대해서 모델 자체를 그냥 다 붙이고 마지막 layer에서 합치기
    - start logit과 end logit을..?


## 조교님이 말씀해주신 질문(정정)
- 딥러닝은 무엇인가요? 딥러닝과 머신러닝의 차이는?
    - 딥러닝 ⊂ 머신러닝 
    - 딥러닝은 신경망/역전파를 사용한다.
    - ~~CPU/GPU 활용의 차이~~ => **(멘토님 답변)** 요즘은 머신러닝에서도 GPU를 많이 활용하고 있으며, 연산량 측면에서 일반적으로 딥러닝이 더 크긴 함.
    - 딥러닝은 심층신경망을 사용하게 되면서 기존의 머신러닝 모델에 비하여 블랙박스 속성이 강해졌다.
- 왜 갑자기 딥러닝이 부흥했을까요?
    - 데이터의 양이 많아지고 수집 경로도 다양해짐 (딥러닝은 머신러닝에 비해 데이터 크기가 커질수록 성능이 향상하는 경향)
    - GPU 성능 향상으로 큰 모델 구동이 가능해짐
    - 역전파 알고리즘이 잘 동작하게 됐습니다. ( 잘 초기화하는 방법을 발견함 )
    - ( 이건 엄청 중요하지는 않지만 ) 이름을 딥러닝으로 지은 것도 어느 정도 영향이 있다고 합니다.. ㅎ
    - 인간의 편향을 믿을바에야 컴퓨터의 연산 과정을 믿자는 의도에서
    - 사람이 일일이 feature를 뽑아낼 필요가 없었기 때문에
- ReLU의 장/단점? (연산, 수렴속도 측면은 어떤가요?)
  **(멘토님 의견)** 기존에 존재하는 것에 의구심을 가져보았는가?
    - Activation 계산이 굉장히 간단합니다.
    - gradient vanishing 현상이 sigmoid/tanh에 비해 없다.
    - 0 이하의 값은 모두 gradient가 0이 되어 많은 정보가 소실될 수 있다
- ReLU 이후에 나온 activation function들 아는 것
  **(멘토님 의견)** 최신 논문을 잘 읽고 있나?
    - GeLU
    - Leaky Relu
    - SeLU
- 왜 bias가 필요할까요? 
  **(멘토님 답변)** bias가 없으면 0이 들어왔을 때 무조건 0이 나가므로 해당 뉴런(노드)의 학습이 진행되지 않는다. 특정 노드가 의도치않게 계속 dropout됨. 딥러닝 개념 자체가 사람의 신경 구조에서 빌려온 면이 있으며, 사람도 비슷하게 편향성을 가지기 때문에 필요.
  **(질문 의도)** (아래 질문까지) 기존에 존재하는 기법에 의문을 가져보았는가?
    - 실세계에 존재하는 데이터셋에 이미 bias가 존재하기 때문입니다.
    - bias를 측정할 수 있으면 예측한 값과 실제값의 차이를 bias만큼 조정해 실제값에 근사할 수 있다?
    - 데이터만으로 설명할 수 없는 부분을 모델에 포함시키기 위해
- 왜 bias라는 이름이 붙었을까요?
    - 모델의 예측으로부터 양으로 혹은 음으로 치우치게 만들어서(?)
    - bias => 편향 => 전체를 이동시키는 느낌..?
        - activation을 적용할 경계 대신 편향성을 이용하는 것 같음 
- CNN에서 Activation, Batch normalization, Convolution layer, Dropout, Maxpooling 배치순서
  **(질문 의도)** 실제 논문을 구현해보았나?
    - Batch Normalization - Convolution Layer - Maxpooling - Activation - Dropout
    - Dropout - Conv - BatchNorm - Activation - MaxPool
    - Dropout -> Batch Norm -> Conv -> Maxpooling -> Activation
    - **(ResNet 기준)** Conv - BatchNorm - Activation - MaxPool
- 학습에 메모리가 부족하다, 네트워크를 줄일 것인가 배치 사이즈를 줄일 것인가? (정답은 없고, 어떻게 의견이 다른 상대방을 나만의 논리로 설득할 수 있을지가 포인트입니다.)
  **(질문 의도)** (아래 질문까지) 머신러닝 문제를 많이 풀어보았나?
    - 네트워크 크기를 줄이고, Batch Size는 gradient accumulation으로 해결한다. <- 한표, 두표
        - 네트워크 크기를 줄이는 이유는 학습 데이터의 영향을 키우기 위해서
    - 데이터가 소량인 경우 네트워크를 줄일 듯
- 트레이닝 데이터가 1000개, 테스트 데이터가 100000개이다. 최대 성능을 내기 위해 어떻게 해야할까? (위와 같습니다)
  **(질문 의도)** 머신러닝 문제 많이 풀어보았나를 묻는 문제
    - 트레이닝 데이터로 학습 후에
        - Confidence가 높은 데이터는 Pseudo Labeling
        - Confidence가 낮은 데이터는 직접 Labeling을 함으로써 Train 데이터의 절대적인 크기를 늘린다.
        - **(멘토님 답변)** Kaggle에서 몇년 전까지 우승했던 팀들이 많이 사용했던 기법이다.
    - 기존의 분포를 고려하며 training data를 oversampling한다
        - augmentation?
    - 비슷한 task에 대해 비슷한 dataset으로 학습한 pretrained model을 찾아본다.
    - 직접 라벨링하여 트레인에 활용한다
    - 유사한 데이터를 활용하거나 minor한 data만 augmentation(oversampling)한다.