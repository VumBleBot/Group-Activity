# 3주차 금요일(0514)

## 어제 까먹고 못한 이슈정리

- (건모) #53 ETRI Dataset EDA
    - 1만개 문서, docs 길이는 차이가 좀 남(ETRI가 좀 짧음)
    - 정답 시작지점은 둘 다 문서 앞쪽
    - 샘플링
        - 문서 길이 기준으로 자름
        - 답변 시작지점도 비슷하게 맞춤 (여기까지 3000개)
        - 문서길이까지 맞추면 1500개밖에 안남아서 거기까진 하지 않음

- (건모) 데이터셋 추가
    - KorQuAD
        - version 1 8천개
        - 문서길이 샘플링 추가된거 4천개 ->4% 성능 향상이 있었음
    - Etri 데이터셋 3000개
    - 데이터셋을 다 섞어서 넣어봤는데 모든 조합에서 성능이 떨어졌음.
        - 과적합 문제가 있지 않을까..?
    - 분포를 바꿔보는건 어떨까?
        - P stage 1, 2에서는 train dataset에 분포를 맞추는게 가장 성능이 좋았기 때문에 이번에도 그렇게 만들려고 했음.

- (종헌) #66 document random masking
    - 정석은 dataloader에서 랜덤으로 masking하는건데, 지금은 trainer를 쓰고있어서..
    - 일단 trainer의 dataloader 파트 오버라이딩하여 구현 예정
    - 만약 구현이 어려우면 모델 내 forward 함수 안에서 data가 들어왔을때 dynamic하게 마스킹

- (건모) #61 bm25 사용하여 qa pair 데이터셋 만든 후 성능 실험해보기
    - 만들긴 했는데 지금은 batch 1로 하지 않으면 안돌아감(데이터 구조 문제인듯)
    - 성능이 안나옴...
    - 일단은 우선순위 미뤄뒀다가 새로운 dense retriever 논문 보면서 구현 예정

- (지영) DPR Retreiver
    - https://huggingface.co/transformers/model_doc/dpr.html#overview
    - haystack 오픈소스도 사용해보려고 하는데... 어렵네요
        - training을 쉽게하려고 파이프라인을 제공해준다고 하는데, 데이터 형식을 맞춰줘야해서.

## PR 논의

- (성익) pororo voting(ensemble)
    - validation에서 무조건 3개의 json 파일 만들도록
        - nbest, predictions, pororo_prediction
    - score도 pororo 적용 전후를 다 볼수 있도록 추가.
    - 수정사항 반영되면 merge

- (수연) ATTIRE BM25
    - 기존에 잘못되어있던 BM25 구현 수정
    - 하이퍼파라미터 best practice 범위내로 하니 잘 동작함
    - 간단한 오류 고치고 merge 예정


## 해야 할 것

- reader 모델 하이퍼파라미터 조정 후 실험(LB까지)
    - lr, 스케줄러, loss 등등
    - config 파일도 공유 가능하면 하기

## 역할분배

- DPR Retreiver : 지영, 건모
    - 지영님 코드 참조해가면서 건모님도 서브로 붙기

- Reader 모델 : 종헌, 성익
    - 모델 구현
        - EM token
        - answer도 embedding vector 만들어서 context에 더해서 학습시키기
        - 아이디어 언제든 말씀 부탁드립니다
    - 모델 학습 방향 설정 (성익)
        - 어떤 데이터를 쓸건지
        - 어떤 방법을 이용해서 data augmentation을 해볼것인가
        - masking을 어떤 방식으로 할것인가...
        - 모델이 좀 더 어려운 문제를 학습할 수 있을까?
        - 쓰앵님이 되겠습니다

- 논문 리뷰 공유 : 수연
    - pretrained 안된 논문
    - 구조가 똑같은 retriever, reader
    - 구현 가능할만한것
    - 서론/구현파트만 skimming 중

- clusterformer 구현 : 건모
    - 데이터 들어가는 방법이 좀 달라서..
    - 여러 subdocument들을 한 batch 안에 같이 줘야함.
    - trainer 내부 함수를 어느정도 봐야함..


## 다음 주에 언제/어디서/누구끼리 만날지!

- 화요일 코어타임(10시-7시)
    - 종헌, 성익, 수연
    - 강남 스터디카페/종일권으로 끊을 수 있는 곳이나...
    - 무중력 지대?
    - 공덕 창업허브!

- 목요일 wrap-up 뒤풀이 ㅎ

## 부캠 회고 작성

잘했던 것/ 좋았던 것/ 계속할 것

- 매일매일 전원이 회의에 적극적으로 참여하고 있습니다.
- 목요일 팀원들과의 줌술타임 좋았습니다. 속상한 점이나 아쉬운 점을 다 얘기하고 속시원하게 대회에 집중할 수 있었습니다.
- slack 알림봇을 만들어 모든 구성원들이 같이 실험결과를 공유하고, 서로 뭘 하는지 알 수 있어서 좋았습니다.
- 협업 프로세스를 체계적으로 구성하였다.
- PR 보내면 다들 댓글달아줘서 좋다.
- 다들 힘든 일이 있을때 위로해준다.
- 하고 있는 모든 것을 기록하고 있다.

잘못했던것/ 아쉬운 것/ 부족한 것 (개선방향)

- 잠을 줄이지 못했다.
- 처음에 대시보드를 구현해뒀어야 했는데 아쉽다.
- 더욱 적극적인 친목도모가 필요하다.
- 적은 인원이라도 오프라인으로 모여서 봤으면 더 좋았을 것 같습니다.
- 일주일밖에 안남았다니 아쉽다..ㅜ_ㅜ
- vumblebot을 아직 못했다...

도전할 것/ 시도할 것

- 오프라인 만남
- 리트리버 베이스라인 탈출
- 리더 모델 개선하기
- 범블봇 프로젝트 시작하기

공부할 것/ 알게된 것/ 느낀 점

- 모델별 토크나이저 결과 비교
- PLM 비교
- Sparse retriever들
- Dense retriever 최신 논문
- 매일 TMI를 공유하며 서로에 대해 많이 알게됨(ㅇㄱㄹㅇ 내적 친밀감)
- 모델 성능에 급급하지 않고, 차근차근 나아가는 것이 중요하다는 것을 느꼈습니다.

