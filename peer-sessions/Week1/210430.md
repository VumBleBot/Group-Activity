# 1주차 금요일 회의(0430)

## 베이스라인 코드 리뷰

### sequence diagaram(건모)

- https://hackmd.io/Anc89gl1S1apVS17RIr7-w

### retrieval.py

    - 이슈 #34 참조
        - np.rand로 생성해서 한번 실험
        - Dense Embedding 실험

### train.py / inference.py

- Training 과정에서 model 바꾸었을 때 `last_checkpoint = None` 한 줄 추가하면 굳이 overwrite argument 주지 않아도 됨!
- `CustomArgument` 추가하여 autoincrement 루프만 추가하면 output_dir의 predictions를 매번 overwrite하지 않고 subdir로 쌓을 수 있음.
- dataset map에서 batch_size 옵션 줄 수 있음
- `offset_mapping` : 해당 index의 token이 실제 context에서 어디에 위치하는지
- `overflow_to_sample_mapping` : max_seq_length 기준으로 잘린 context의 실제 index
- (?) cls_index가 0이 아닌 경우도 있을까?
    - 우리가 가진 데이터셋에서는 그럴일이 없는것같은데, 그냥 예외처리일듯..
    - SQuAD 2.0에서는 빈 답이 있기 때문에 들어가있는 파트.
- `token_start_index`와 `token_end_index`
    - 최초에는 context의 CLS와 SEP으로 범위 지정하고, 두개의 while문으로 좁혀나감
- `prepare_train_features`와 `prepare_validation_features` 차이
    - (?)전자는 offset_mapping 단위로 돌고, 후자는 input_ids 기준으로 도는데 어떤 차이가?
        - 두개가 하는 일이 아예 다른거같음.
- `data_collator` : dynamic하게 padding을 채워주는 객체
- `inference.py`와 `train.py`의 다른점은 retrieve의 유무.

### utils_qa.py

- `postprocess_qa_predictions()` 메서드가 결국 핵심.
    - 핵심 parameter
        - example : 전처리 안된 자연어
        - features : 전처리 된 tokenized vector
    - `feature_indices` : 현재 example에 연관된 모든 feature - 즉, 1개 지문(example)이 길었을 경우 쪼개져서 overlap된 모든 tokenized context의 index들을 가져옴.
    - `token_is_max_content`, `feature_null_score`, `version_2_with_negative` 이런것들 전부 SQuAD 2.0 때문에 들어간 예외처리 관련 변수들. 고로 우리랑 관련없음.