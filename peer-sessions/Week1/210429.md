# 1주차 목요일 회의 (0429)

## 정보탐색

- (종헌) [ALBERT, RoBERTa](../documents/../../documents/further_reading/0429_RoBERTa.ipynb)
    - ALBERT
        - BERT의 학습시간/리소스가 너무 많이 들어 가볍게 만든 버전
    - **RoBERTa**
        - **최적의 하이퍼파라미터로 학습**
        - BERT와의 구조의 차이는 크게 없고, 토크나이저가 Charcter단위 BPE -> Byte단위 BPE
        - input sequence length를 두 문장으로 제한하지 않고 512토큰에 꽉꽉 채워넣음
        - **Dynamic Masking** : 같은 문장이어도 매 epoch마다 랜덤하게 마스킹
        - NSP가 학습에 도움이 되지 않는다고 판단하여 제거 

    - **XLM**
        - XLM : cross-lingual language model, 데이터가 풍부하지 않은 언어를 위한 (**transfer learning** 접목) 다중언어 모델
        - 여러 언어를 같이 embedding하여 마스킹했을 때 서로 다른 언어의 두 parallel 문장을 두고 함.
            - 비슷한 언어는 하나의 embedding 공간에 잘 매칭되었음.
    - **XLM-RoBERTa(XLM-R)** >> mBERT
        - 사용하는 데이터양을 느려서 단일 언어에 대한 성능에 대해서도 RoBERTa와 견줄만함.
            - cross-lingual이 오히려 더 성능이 좋을수도 있다는 점을 시사함
        - 모델 개선보다는 데이터에 의한 성능 개선에 치중한 논문
    - Curse of Multi-lingual
        - 같은 크기 모델이라면 더 많은 언어로 학습할수록 성능이 다소 떨어진다.
        - 모델의 크기가 엄청 커지면 모르겠지만, 당시의 리소스상에서는 그랬다.
        - 그래서 파라미터 조정, 데이터가 없는 language에 대해 upsampling, large shared vocab 생성, capacity 생성으로 해결 시도

- (지영) [Follow up(faiss)](../documents/../../documents/further_reading/0429_faiss.md)  
  
## 1주차 결산

- (건모) SKT KoBERT를 사용해봤는데, 이슈가..
    - transformer에서 제공하는 토크나이저는 use_fast 옵션이 있는데, KoBERT 모델은 use_fast옵션이 없고 offset matching이 안됢.
    - 직접 구현할수도 있긴 한데 pure python이라 불편할것같아서.
- 이슈 칸반보드 정리.
    - 주말내로 끝난것들 closed 처리
    - EDA파트 하고싶은 거 더 있으면 #11에 추가
- Ideas(이슈) 관리
    - #17, #25은 같은 이슈 => 추후 모델 여러개 실험
    - #6은 2주차에 진행
    - #24은 sparse embedding 기준 top-k에서 답이 아닌 것들을 dense에서 더 학습시키는 아이디어(수업에서 나온 아이디어) => 2주차 이후..?
        - 이런거 위해 데이터 정제를 위한 모듈 따로 둘 필요도 있을 것 같음
    - #15은 저번 논문 리뷰 내용 => 추후 실험
    - #19은 이번 주내에 실험 진행

## 다음주 계획

- (앞으로의 계획) dense embedding 기준으로 하는 것을 목표로 하되, 추후에는 sparse embedding도 함께 사용하여 정확도를 높여볼 수 있을 것 같음
    - [참고](https://github.com/danqi/acl2020-openqa-tutorial/blob/master/slides/part5-dense-retriever-e2e-training.pdf)
  
## 범블봇

- [ ] Extractive OR Generative
    - Extractive: 노래를 찾아내는 것
        - 입력: 질문 / 질문 혹은 그냥 평서문(우울할 때 들을 노래 추천해줘./나 너무 우울해.)
            - 질문: (@vumblebot), ~ 한 노래 찾아줘
            - 자연어: 안녕, 밥 먹었어, =? 노래 추천? 
            - 심리 챗봇 데이터 사용
                - 심리 챗봇 데이터의 질문과 유사하다고 판단될 경우 노래 추천
                - EX) 아 너무 우울해 => 노래 추천 해줄까?
                - EX) 안녕~ => 안녕~
            - (성익) 명령어만 들어간다면 어떠한 문장이 들어와도 상관없다.
            - (초기 아이디어) Dense Retriever로 Embedding
        - 문서 탐색: 전체 노래 제목 + 가사
            - Dense Retriever로 Embedding
        - 문서 내 탐색(Extractive MRC): 문서에서 가장 유사한 가사 추출
        - 출력: 가사 구절 ( 뭘 출력하든 간에 relevance score 1등 문서 사용 )
        - Retriever-only
        - 데이터: 가사문서(제목 붙은)
        
        - 직접 100개의 데이터 셋을 만들어서 Confidence별로
        - 성익: 답변을 만든다면 감정 매칭이 어려울 것 같다.
        
    - Generative: 답변을 생성해는 것

 - 문제: 라벨링된 데이터셋을 어떻게 구축해야 할지?
     - 심리챗봇 답변 데이터에서 노래 정보를 추출하는 방법
     - 지도학습 및 비지도 학습 전체 고려해서 생각
 
 - 일단 아이디어가 생기면 슬랙에 올리는걸로 하고 시간 있을 때 주제는 다시 얘기해보기로 함
  
## 기록할 것

- (성익) 목요일 3시-5시15분 실강. 5시이전에 보통 끝나서 혹시 목요일만 피어세션 시간 바꿀 수 있을지.. 넹
- (신용섭 운영진님) GPU 문제 / 디스크 문제 질의응답 채널에 올려서 공론화해주세요ㅠㅠ
  
## 해야할 것

- [ ] [ETRI KorBERT 신청!](https://aiopen.etri.re.kr/service_dataset.php)
- [ ] 내일(4/30) 베이스라인 코드 리뷰
